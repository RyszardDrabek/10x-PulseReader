# Plan Test√≥w dla Projektu PulseReader

> **üìã Status:** ‚úÖ Zaktualizowany (v2.0) - Listopad 17, 2025  
> **üìñ Szczeg√≥≈Çy zmian:** Zobacz sekcjƒô 11 na ko≈Ñcu dokumentu

## 1. Wprowadzenie i Cele Testowania

Plan test√≥w dla projektu PulseReader, inteligentnego agregatora wiadomo≈õci, ma na celu zapewnienie wysokiej jako≈õci oprogramowania, kt√≥re spe≈Çnia wymagania funkcjonalne i niefunkcjonalne. Projekt opiera siƒô na agregacji tre≈õci z RSS, zarzƒÖdzaniu u≈ºytkownikami, analizie AI oraz personalizacji feedu, co wymaga kompleksowego podej≈õcia do weryfikacji.

**Cele testowania:**
- Weryfikacja poprawno≈õci implementacji kluczowych funkcjonalno≈õci, takich jak autentykacja, pobieranie i filtrowanie artyku≈Ç√≥w oraz integracja z AI.
- Zapewnienie bezpiecze≈Ñstwa, wydajno≈õci i u≈ºyteczno≈õci aplikacji w ≈õrodowisku webowym.
- Identyfikacja i minimalizacja defekt√≥w przed wdro≈ºeniem, z naciskiem na integracje zewnƒôtrzne (Supabase, OpenRouter.ai).
- OsiƒÖgniƒôcie co najmniej 80% pokrycia kodu testami jednostkowymi i integracyjnymi.
- Potwierdzenie zgodno≈õci z najlepszymi praktykami TypeScript i Astro, w tym responsywno≈õci UI.

Testy bƒôdƒÖ prowadzone iteracyjnie, r√≥wnolegle z rozwojem, aby wspieraƒá proces CI/CD za pomocƒÖ GitHub Actions.

## 2. Zakres Test√≥w

Zakres obejmuje wszystkie warstwy aplikacji: frontend (Astro pages i React components), backend (API endpoints i us≈Çugi), bazƒô danych (Supabase) oraz integracje zewnƒôtrzne (RSS, AI).

**W zakresie:**
- Funkcjonalno≈õci u≈ºytkownika: rejestracja, logowanie, wylogowanie, zarzƒÖdzanie profilem (nastr√≥j, blocklist).
- Agregacja tre≈õci: pobieranie z RSS, analiza AI (sentyment, tematy), filtrowanie i paginacja artyku≈Ç√≥w.
- Interfejs: infinite scroll, responsywno≈õƒá, obs≈Çuga b≈Çƒôd√≥w UI.
- API: walidacja parametr√≥w, autoryzacja, obs≈Çuga b≈Çƒôd√≥w (np. Zod).
- Bezpiecze≈Ñstwo: ochrona przed nieautoryzowanym dostƒôpem, walidacja danych wej≈õciowych.
- Wydajno≈õƒá: ≈Çadowanie feedu, zapytania do bazy.

**Poza zakresem (dla MVP):**
- Testy obciƒÖ≈ºeniowe na du≈ºƒÖ skalƒô (ponad 1000 u≈ºytkownik√≥w jednocze≈õnie).
- Testy mobilne natywne (tylko web responsywny).
- Testy dostƒôpno≈õci dla specjalistycznych czytnik√≥w ekranu (podstawowa weryfikacja ARIA).

## 3. Typy Test√≥w do Przeprowadzenia

- **Testy jednostkowe:** Weryfikacja pojedynczych funkcji i komponent√≥w (np. ArticleService, React components). Pokrycie: metody walidacji, logiki filtrowania.
- **Testy integracyjne:** Sprawdzenie interakcji miƒôdzy modu≈Çami (np. API z Supabase, middleware z auth). Mockowanie zewnƒôtrznych API (RSS, OpenRouter).
- **Testy end-to-end (E2E):** Symulacja pe≈Çnych flow u≈ºytkownika (np. logowanie ‚Üí filtrowanie feedu ‚Üí klikniƒôcie artyku≈Çu) za pomocƒÖ Playwright.
- **Testy wydajno≈õciowe:** Pomiar czasu ≈Çadowania stron, zapyta≈Ñ DB i API (np. infinite scroll dla 100 artyku≈Ç√≥w). Narzƒôdzie: Lighthouse.
- **Testy bezpiecze≈Ñstwa:** Skanowanie na SQL injection, XSS (np. w opisach artyku≈Ç√≥w), testy autoryzacji (OWASP ZAP).
- **Testy UI/UX:** Snapshot testing dla komponent√≥w React, visual regression (np. zmiany w Tailwind/Shadcn).
- **Testy regresji:** Automatyczne po ka≈ºdej zmianie w CI/CD, skupione na krytycznych ≈õcie≈ºkach (auth, articles).

Testy bƒôdƒÖ zautomatyzowane w 90% przypadk√≥w, z manualnymi spot-checks dla UX.

## 4. Scenariusze Testowe dla Kluczowych Funkcjonalno≈õci

### Autentykacja i ZarzƒÖdzanie U≈ºytkownikami
- SC-001: Rejestracja nowego u≈ºytkownika z poprawnymi danymi ‚Üí sukces, email weryfikacyjny.
- SC-002: Logowanie z niepoprawnymi credentials ‚Üí b≈ÇƒÖd 400, brak dostƒôpu do chronionych rout.
- SC-003: Wylogowanie ‚Üí czyszczenie sesji, redirect do login.
- SC-004: Middleware blokuje dostƒôp do /profile bez auth ‚Üí redirect do /login.
- SC-005: Aktualizacja profilu (nastr√≥j, blocklist) ‚Üí persistencja w Supabase, zastosowanie w filtrach.

### Agregacja i Filtrowanie Artyku≈Ç√≥w
- SC-006: Pobieranie artyku≈Ç√≥w z RSS (cron job) ‚Üí nowe wpisy w DB, unikalno≈õƒá po linku.
- SC-007: Analiza AI artyku≈Çu ‚Üí przypisanie sentymentu/temat√≥w, obs≈Çuga b≈Çƒôd√≥w API OpenRouter.
- SC-008: Filtrowanie feedu po nastroju (positive) ‚Üí tylko artyku≈Çy positive/neutral, infinite scroll.
- SC-009: Personalizacja z blocklist ‚Üí wykluczenie zablokowanych s≈Ç√≥w/domen, over-fetching dla kompensacji.
- SC-010: Paginacja API /articles?limit=20&offset=20 ‚Üí poprawne dane, hasMore flag.

### Interfejs U≈ºytkownika
- SC-011: Wy≈õwietlenie homepage dla go≈õcia ‚Üí niepersonalizowany feed, brak b≈Çƒôd√≥w.
- SC-012: Infinite scroll w ArticleList ‚Üí ≈Çadowanie kolejnych partii bez duplikat√≥w.
- SC-013: Responsywno≈õƒá na mobile ‚Üí menu, karty artyku≈Ç√≥w dostosowane (Tailwind breakpoints).
- SC-014: Obs≈Çuga pustego feedu ‚Üí przyjazny komunikat, sugestie filtr√≥w.

### Integracje Zewnƒôtrzne
- SC-015: Mock RSS fetch ‚Üí symulacja b≈Çƒôd√≥w (404, timeout) ‚Üí graceful degradation.
- SC-016: AI call do OpenRouter ‚Üí walidacja JSON response, fallback dla b≈Çƒôd√≥w.

Ka≈ºdy scenariusz obejmuje przypadki pozytywne, negatywne i edge (np. puste dane, max d≈Çugo≈õƒá blocklist).

## 5. ≈örodowisko Testowe

- **Lokalne:** Node.js 22.x, Supabase lokalny (docker), mock serwery dla RSS/OpenRouter (msw).
- **Staging:** Supabase project (oddzielny od prod), DigitalOcean droplet, zmienne env z testowymi kluczami API.
- **Produkcyjne:** Monitorowanie po deployu via GitHub Actions, rollback je≈õli >5% b≈Çƒôd√≥w.
- Konfiguracja: Port 3000 dla dev, HTTPS w staging/prod. Baza testowa z seed data (przyk≈Çadowe artyku≈Çy, users).

≈örodowiska izolowane, z automatycznym czyszczeniem po testach (np. truncate tables).

## 6. Narzƒôdzia do Testowania

### 6.1 Testy Jednostkowe i Integracyjne
- **Framework:** Vitest 2.x (natywna integracja z Vite/Astro, szybszy ni≈º Jest)
- **Environment:** happy-dom (l≈ºejszy ni≈º jsdom)
- **React Testing:** @testing-library/react + @testing-library/user-event
- **Coverage:** @vitest/coverage-v8 (target: 80% line coverage)
- **Walidacja:** Zod (ju≈º u≈ºywane w projekcie)
- **Database:** Supabase Local Development (prawdziwa PostgreSQL w testach)

### 6.2 Testy E2E
- **Framework:** Playwright 1.x (cross-browser: Chromium, Firefox, WebKit)
- **Features:** Trace viewer, auto-waiting, screenshots/video on failure
- **Mobile:** Pixel 5, iPhone 13 emulation
- **Reporters:** HTML, JSON, GitHub Actions

### 6.3 Wydajno≈õƒá
- **Performance:** Lighthouse CI z bud≈ºetami (FCP <2s, LCP <2.5s, TTI <3.5s)
- **Load Testing:** k6 (Grafana) - scripting w JavaScript, metryki dla 50+ concurrent users
- **Monitoring:** p95 latency <500ms, p99 <1000ms

### 6.4 Bezpiecze≈Ñstwo
- **Dependencies:** Snyk (skanowanie npm packages, integracja z GitHub)
- **Vulnerabilities:** Trivy (lekki scanner CVE, darmowy dla open-source)
- **Built-in:** npm audit (zero konfiguracji)
- **Target:** 0 high/critical vulnerabilities przed mergem

### 6.5 UI i Visual Regression
- **Component Testing:** React Testing Library (behavior-driven)
- **Component Library:** Historia (Astro-native, l≈ºejsza ni≈º Storybook)
- **Visual Regression:** Playwright Visual Comparisons (wbudowane, pixel-by-pixel)
- **Baseline:** Snapshots w repo, diff checking w CI

### 6.6 API Mocking
- **Framework:** MSW v2 (Mock Service Worker)
- **Mocks:** RSS feeds, OpenRouter.ai, zewnƒôtrzne API
- **≈örodowiska:** Node (testy) i browser (development)

### 6.7 CI/CD i Raportowanie
- **Pipeline:** GitHub Actions (free dla public repos)
- **Artifacts:** Test results, coverage reports, Playwright traces
- **Raporty:** 
  - Vitest UI (interaktywny dashboard lokalnie)
  - Playwright HTML Report (hosted w GitHub artifacts)
  - GitHub Checks (‚úÖ/‚ùå status w PR)
- **Notifications:** GitHub native (brak zewnƒôtrznych serwis√≥w)

### 6.8 Test Data i Utilities
- **Fixtures:** Test Data Builders pattern
- **Faker:** @faker-js/faker dla generowania danych
- **Helpers:** Custom render z providers (QueryClient, Theme)

**Integracja:** Wszystkie narzƒôdzia dostƒôpne przez npm scripts (test, test:e2e, test:coverage, test:ui)

**Oszczƒôdno≈õci:** ~$1,688/rok vs tradycyjne rozwiƒÖzania (Percy, Allure hosting, OWASP ZAP infra)

## 7. Harmonogram Test√≥w

Testy iteracyjne w ramach sprint√≥w (2-tygodniowe):

### Faza 1: Setup i Testy Jednostkowe (Tydzie≈Ñ 1-2)
**Czas: 40 godzin**
- ‚úÖ Instalacja i konfiguracja: Vitest, happy-dom, React Testing Library, MSW v2
- ‚úÖ Setup plik√≥w: `vitest.config.ts`, `src/__tests__/setup.ts`, mock handlers
- ‚úÖ Supabase Local Development: konfiguracja test DB, seed scripts
- ‚úÖ Testy jednostkowe:
  - Auth service (register, login, logout)
  - ArticleService (CRUD operations, filtering)
  - Validators (Zod schemas)
- ‚úÖ Test Data Builders: fixtures i helpers
- **Target:** 70% code coverage, wszystkie service testy przechodzƒÖ

### Faza 2: Testy Integracyjne i E2E (Tydzie≈Ñ 3-4)
**Czas: 50 godzin**
- ‚úÖ Playwright setup: instalacja, konfiguracja cross-browser
- ‚úÖ Testy integracyjne:
  - API endpoints (`GET/POST /api/articles`, `/api/auth/*`)
  - Database operations (joins, transactions, RLS policies)
  - Middleware (auth, error handling)
- ‚úÖ E2E flows:
  - User registration ‚Üí verification ‚Üí login
  - Article browsing ‚Üí filtering ‚Üí infinite scroll
  - Profile management ‚Üí personalization
- ‚úÖ Mobile testing: Pixel 5, iPhone 13 scenarios
- **Target:** 80% unit coverage, 60% E2E coverage, 0 krytycznych bug√≥w

### Faza 3: Performance, Security, Visual (Tydzie≈Ñ 5)
**Czas: 30 godzin**
- ‚úÖ Load testing (k6):
  - Baseline: 10 concurrent users
  - Target: 50 concurrent users, <500ms p95
  - Spike test: 100 users, graceful degradation
- ‚úÖ Security scans:
  - Snyk: dependency vulnerabilities
  - Trivy: CVE scanning
  - npm audit: quick checks
- ‚úÖ Visual regression:
  - Playwright snapshots dla kluczowych stron
  - Baseline generation
  - CI integration
- ‚úÖ Lighthouse CI:
  - Performance budgets
  - Accessibility checks (basic ARIA)
- **Target:** <5% failed requests, 0 high/critical CVEs, LCP <2.5s

### Faza 4: CI/CD i Stabilizacja (Tydzie≈Ñ 6)
**Czas: 20 godzin**
- ‚úÖ GitHub Actions workflow:
  - Unit tests na ka≈ºdym PR
  - E2E tests na push do main/develop
  - Security scans (weekly)
  - Performance tests (pre-deploy)
- ‚úÖ Coverage reporting: Codecov integration
- ‚úÖ Artifacts: test results, Playwright traces, HTML reports
- ‚úÖ Dokumentacja:
  - README z instrukcjami
  - Contributing guide (jak pisaƒá testy)
  - Troubleshooting common issues
- ‚úÖ Code review: przeglƒÖd wszystkich test√≥w
- ‚úÖ Buffer: bugfixy, optymalizacje, edge cases
- **Target:** Pe≈Çna automatyzacja, 0 flaky tests

### CiƒÖg≈Çe (Post-MVP)
- **Na ka≈ºdym PR:** Unit + integration tests, linting, type-checking
- **Na merge do main:** Pe≈Çna suita E2E, security scan
- **Weekly:** Load testing, visual regression full suite
- **Monthly:** Dependency updates, test maintenance

**Ca≈Çkowity czas:** 140 godzin (6 tygodni)  
**Buffer:** 20% (~30h) na nieprzewidziane problemy  
**Oszczƒôdno≈õƒá vs oryginalny plan:** 20-100 godzin dziƒôki l≈ºejszym narzƒôdziom

## 8. Kryteria Akceptacji Test√≥w

### 8.1 Funkcjonalne
- ‚úÖ **100% krytycznych scenariuszy** przechodzi bez b≈Çƒôd√≥w:
  - Rejestracja + weryfikacja email
  - Logowanie + sesja + wylogowanie
  - Pobieranie artyku≈Ç√≥w (filtrowanie, paginacja, sorting)
  - Personalizacja (mood, blocklist)
- ‚úÖ **<5% defekt√≥w krytycznych** (blocker/critical severity)
- ‚úÖ **0 flaky tests** (max 1% retry rate)

### 8.2 Pokrycie Kodu
- ‚úÖ **Unit/Integration:** >80% line coverage, >75% branch coverage
  - Services: >85%
  - API endpoints: >80%
  - Validators: 100%
- ‚úÖ **E2E:** >70% critical user paths
  - Auth flows: 100%
  - Article operations: >80%
  - Profile management: >70%
- ‚úÖ **Narzƒôdzie:** Vitest coverage (v8 provider), raporty w Codecov

### 8.3 Wydajno≈õƒá
- ‚úÖ **Homepage (Lighthouse CI):**
  - First Contentful Paint (FCP): <2s
  - Largest Contentful Paint (LCP): <2.5s
  - Time to Interactive (TTI): <3.5s
  - Cumulative Layout Shift (CLS): <0.1
- ‚úÖ **API (k6 load tests):**
  - p50 latency: <150ms
  - p95 latency: <500ms
  - p99 latency: <1000ms
  - Error rate: <5% przy 50 concurrent users
- ‚úÖ **Database queries:** <100ms dla pojedynczych SELECT, <200ms dla JOIN

### 8.4 Bezpiecze≈Ñstwo
- ‚úÖ **Vulnerabilities (Snyk + Trivy):**
  - 0 critical (CVSS 9.0-10.0)
  - 0 high (CVSS 7.0-8.9)
  - <5 medium (CVSS 4.0-6.9) z planem naprawy
- ‚úÖ **npm audit:** 0 high/critical w production dependencies
- ‚úÖ **Auth testing:**
  - JWT validation: 100% coverage
  - Unauthorized access: wszystkie scenariusze zablokowane
  - SQL injection: brak podatno≈õci (Supabase prepared statements)
  - XSS: DOMPurify dla wszystkich user inputs

### 8.5 UI i Visual Regression
- ‚úÖ **Component tests:** 100% dla UI library (Shadcn components)
- ‚úÖ **Visual regression (Playwright):**
  - 0 pixel diff dla unchanged pages
  - <100px diff tolerance dla dynamic content
  - Baseline snapshots w repo
- ‚úÖ **Responsiveness:**
  - Desktop (1920x1080): ‚úÖ
  - Tablet (768x1024): ‚úÖ
  - Mobile (375x667): ‚úÖ
- ‚úÖ **Accessibility (basic):**
  - ARIA labels present
  - Keyboard navigation works
  - Color contrast ratio >4.5:1

### 8.6 CI/CD
- ‚úÖ **GitHub Actions:**
  - Build time: <5min
  - Test execution: <3min (unit+integration), <8min (E2E)
  - 100% green runs (no intermittent failures)
- ‚úÖ **PR checks:**
  - Linting: 0 errors
  - Type checking: 0 TypeScript errors
  - Tests: wszystkie przechodzƒÖ
  - Coverage: nie spada poni≈ºej thresholdu
- ‚úÖ **Artifacts:** Test reports, coverage, traces dostƒôpne przez 30 dni

### 8.7 Dokumentacja Test√≥w
- ‚úÖ **README:** Instrukcje uruchomienia test√≥w (local + CI)
- ‚úÖ **Contributing:** Guidelines pisania test√≥w
- ‚úÖ **Test files:** Docstrings wyja≈õniajƒÖce co testujƒÖ
- ‚úÖ **Troubleshooting:** Common issues i solutions

### 8.8 Blocker Criteria (ZatrzymujƒÖ Merge/Deploy)
- ‚ùå Jakiekolwiek failing critical tests
- ‚ùå Coverage drop >5%
- ‚ùå High/critical security vulnerabilities
- ‚ùå Performance regression >20%
- ‚ùå Visual regressions bez approve
- ‚ùå CI/CD pipeline broken

**Wszystkie kryteria muszƒÖ byƒá spe≈Çnione przed mergem do main i deployem do produkcji.**

## 9. Role i Odpowiedzialno≈õci w Procesie Testowania

- **QA Lead (In≈ºynier QA):** Tworzenie planu, scenariuszy, raportowanie; nadz√≥r nad automatyzacjƒÖ.
- **Developerzy:** Pisanie unit tests dla swoich modu≈Ç√≥w (TDD), fix defekt√≥w.
- **DevOps:** Konfiguracja CI/CD, ≈õrodowisk testowych; monitoring wydajno≈õci.
- **Product Owner:** Priorytetyzacja scenariuszy, akceptacja kryteri√≥w; review manual tests.
- **Zesp√≥≈Ç:** Code review test√≥w, udzia≈Ç w E2E sessions.

Wsp√≥≈Çpraca via GitHub issues (etykiety: bug, test-needed).

## 10. Procedury Raportowania B≈Çƒôd√≥w i Metryki

### 10.1 Rejestracja Defekt√≥w
**Narzƒôdzie:** GitHub Issues z dedykowanym template

**Bug Report Template:**
```markdown
## Bug Description
[Opis problemu w 1-2 zdaniach]

## Steps to Reproduce
1. 
2. 
3. 

## Expected Behavior
[Co powinno siƒô staƒá]

## Actual Behavior
[Co siƒô sta≈Ço]

## Environment
- Browser/Device: 
- OS: 
- Version: 

## Screenshots/Logs
[Wklej screenshots lub logi]

## Test Case
- [ ] Unit test reproducing issue
- [ ] E2E test added

## Priority
- [ ] P1 - Critical (blocker, production down)
- [ ] P2 - High (major feature broken)
- [ ] P3 - Medium (workaround exists)
- [ ] P4 - Low (minor issue, cosmetic)

## Severity
- [ ] Critical - Data loss, security breach
- [ ] High - Feature completely broken
- [ ] Medium - Feature partially broken
- [ ] Low - UI issue, typo
```

### 10.2 Klasyfikacja i Priorytetyzacja

**Priority Matrix:**
| Priority | Response Time | Fix Timeline | Deploy |
|----------|--------------|--------------|--------|
| P1 - Critical | <1h | <4h | Hotfix immediate |
| P2 - High | <4h | <24h | Next patch |
| P3 - Medium | <24h | <1 week | Next sprint |
| P4 - Low | <1 week | Backlog | When convenient |

**Labels:**
- `bug` - Defekt w istniejƒÖcej funkcjonalno≈õci
- `regression` - Wcze≈õniej dzia≈Ça≈Ço, teraz nie dzia≈Ça
- `security` - Zagro≈ºenie bezpiecze≈Ñstwa
- `performance` - Problem z wydajno≈õciƒÖ
- `flaky-test` - Test przechodzi/nie przechodzi losowo
- `test-needed` - Wymaga dodania testu

### 10.3 ≈öledzenie i Workflow

**GitHub Projects Board:**
```
Columns:
1. üÜï New (nowe issues)
2. üîç Triaged (zweryfikowane, przypisane)
3. üèóÔ∏è In Progress (w trakcie fixu)
4. ‚úÖ Fixed (fix gotowy, czeka na review)
5. üß™ Testing (weryfikacja QA)
6. ‚úîÔ∏è Closed (zweryfikowane, zamkniƒôte)
```

**Workflow:**
1. **Bug spotted** ‚Üí Create GitHub Issue (auto-assign to QA Lead)
2. **Triage** ‚Üí QA Lead verifies, adds labels, assigns developer
3. **Fix** ‚Üí Developer creates branch, fixes, adds test
4. **PR** ‚Üí Code review + automated tests w CI
5. **Verify** ‚Üí QA runs regression suite
6. **Close** ‚Üí Merge to main, close issue

### 10.4 Automatyczne Raporty

**GitHub Actions Artifacts:**
- **Test Results:** JSON z Vitest (test-results.json)
- **Coverage Reports:** HTML + LCOV dla Codecov
- **Playwright Reports:** HTML z traces, screenshots, videos
- **k6 Results:** JSON z metrykami performance
- **Security Scans:** Snyk/Trivy SARIF files

**Codecov Dashboard:**
- Coverage trends (per PR, per branch)
- Diff coverage (nowy kod vs istniejƒÖcy)
- File-level coverage (kt√≥re pliki majƒÖ niski %)

**GitHub Insights:**
- Pull Request metrics (time to merge, review time)
- Issue metrics (open/closed ratio, resolution time)
- Code frequency (additions/deletions)

### 10.5 Eskalacja Krytycznych B≈Çƒôd√≥w

**P1 Critical Bugs:**
1. **Detection:** CI pipeline fail LUB production monitoring alert
2. **Notification:** GitHub Issue auto-tagged `P1-critical` + `security` (if applicable)
3. **Response:** Dev Lead notified immediately
4. **Fix:** Hotfix branch created, bypass normal PR process
5. **Testing:** Minimal regression suite (critical paths only)
6. **Deploy:** Direct to production with monitoring
7. **Post-mortem:** Root cause analysis, preventive measures

**Communication Channels:**
- GitHub Issues (primary)
- GitHub Discussions (dla pyta≈Ñ)
- PR comments (dla code-specific issues)

### 10.6 Metryki i KPI

**Weekly Metrics (auto-generated via GitHub Actions):**

```yaml
# .github/workflows/metrics.yml
name: Weekly Metrics
on:
  schedule:
    - cron: '0 9 * * 1'  # Every Monday 9am

jobs:
  collect-metrics:
    runs-on: ubuntu-latest
    steps:
      - name: Generate Metrics
        run: |
          echo "## Test Metrics (Last 7 Days)" > metrics.md
          echo "- Tests Run: $(gh run list --limit 50 --json conclusion | jq '.' | wc -l)" >> metrics.md
          echo "- Success Rate: $(gh run list --limit 50 --json conclusion | jq '[.[] | select(.conclusion=="success")] | length')" >> metrics.md
          echo "- Coverage: $(curl -s https://codecov.io/api/gh/.../coverage | jq .coverage)" >> metrics.md
```

**Dashboard KPIs:**
- **Test Stability:** % test√≥w passing (target: >99%)
- **Coverage Trend:** Line coverage over time (target: >80%)
- **Bug Resolution Time:** Avg time to close (target: <48h dla P2)
- **Flaky Test Rate:** % test√≥w z >1 retry (target: <1%)
- **Security Posture:** CVE count (target: 0 high/critical)
- **Performance:** p95 latency trend (target: stable)

### 10.7 Retrospektywy i Continuous Improvement

**Monthly Test Review Meeting:**
- Review top 10 longest-running tests (optimization opportunities)
- Analyze flaky tests (fix or remove)
- Coverage gaps (untested modules)
- New test types needed (based on production bugs)
- Tool updates (Vitest, Playwright versions)

**Quarterly:**
- Full test suite audit
- Performance baseline update
- Security scan policy review
- CI/CD pipeline optimization

**Raporty dostƒôpne:**
- GitHub Actions artifacts (30 dni retention)
- Codecov dashboards (unlimited history)
- GitHub Insights (built-in, free)
- Lokalne raporty: `playwright-report/`, `coverage/`

**Brak zewnƒôtrznych narzƒôdzi do raportowania** ‚Äì wszystko w GitHub ekosystemie dla prostoty i 0 koszt√≥w.

---

## 11. Podsumowanie Aktualizacji Planu (Listopad 2025)

### 11.1 Zmiany w Stosie Technologicznym

**ZastƒÖpione Narzƒôdzia:**

| Oryginalny Plan | Nowa Rekomendacja | Uzasadnienie Zmiany |
|----------------|-------------------|---------------------|
| **OWASP ZAP** | **Snyk + Trivy + npm audit** | ‚Ä¢ OWASP ZAP wymaga Java, trudny w CI/CD<br>‚Ä¢ Snyk: dedykowany dla npm, lepsze wsparcie<br>‚Ä¢ Trivy: lekki, szybki, darmowy dla OS<br>‚Ä¢ ≈Åatwiejsza automatyzacja |
| **Artillery** | **k6 (Grafana Labs)** | ‚Ä¢ k6 szybszy (Go vs Node.js)<br>‚Ä¢ Scripting w JavaScript (znajome dla zespo≈Çu)<br>‚Ä¢ Lepsze metryki i dokumentacja<br>‚Ä¢ Aktywna spo≈Çeczno≈õƒá |
| **Percy** | **Playwright Visual Comparisons** | ‚Ä¢ Percy: $99/miesiƒÖc ($1,188/rok)<br>‚Ä¢ Playwright: wbudowane, darmowe<br>‚Ä¢ Pixel-by-pixel comparison<br>‚Ä¢ Snapshots w repo (brak external service) |
| **Allure** | **GitHub Actions Native + Vitest UI + Playwright HTML** | ‚Ä¢ Allure wymaga Java + hosting<br>‚Ä¢ Natywne raporty: zero setup<br>‚Ä¢ GitHub artifacts: darmowe<br>‚Ä¢ Integracja z PR checks |
| **Storybook** | **Historia** | ‚Ä¢ Storybook: konflikty z Astro/Vite<br>‚Ä¢ Historia: zaprojektowana dla Vite<br>‚Ä¢ L≈ºejsza, szybszy start<br>‚Ä¢ Lepsze TypeScript support |

**Dodane Narzƒôdzia:**

- **MSW v2:** Mock Service Worker dla RSS/OpenRouter.ai API (brak w oryginalnym planie)
- **happy-dom:** Environment dla Vitest (l≈ºejszy ni≈º jsdom)
- **@faker-js/faker:** Generowanie test data
- **Supabase Test Helpers:** Oficjalne utilities dla test√≥w z Supabase
- **Codecov:** Coverage tracking i reporting (darmowe dla OS)

**Zachowane (Bez Zmian):**

- ‚úÖ Vitest (unit/integration)
- ‚úÖ Playwright (E2E)
- ‚úÖ React Testing Library
- ‚úÖ GitHub Actions (CI/CD)
- ‚úÖ Zod (walidacja)
- ‚úÖ Lighthouse CI (performance)

### 11.2 Korzy≈õci z Aktualizacji

**Finansowe:**

- **Oszczƒôdno≈õƒá roczna:** ~$1,688
  - Percy: $1,188/rok
  - Allure hosting: $300/rok
  - OWASP ZAP infrastructure: $200/rok
- **Koszt nowych narzƒôdzi:** $0 (wszystkie open-source/darmowe)

**Czasowe:**

- **Oszczƒôdno≈õƒá setup time:** ~20 godzin
  - Brak Java setup (OWASP ZAP, Allure)
  - Uproszczona konfiguracja
  - Mniej zewnƒôtrznych zale≈ºno≈õci
- **Oszczƒôdno≈õƒá execution time:** ~15%
  - k6 szybszy od Artillery
  - Vitest szybszy od Jest
  - Playwright native visual diffs

**Jako≈õciowe:**

- **Lepsza integracja z stackiem:** Wszystkie narzƒôdzia native dla Vite/Astro
- **Mniej vendor lock-in:** Open-source tools, brak p≈Çatnych serwis√≥w
- **Prostsza architektura:** Wszystko w GitHub ecosystem
- **≈Åatwiejszy onboarding:** Mniej narzƒôdzi do nauki

### 11.3 Wymagane Dzia≈Çania przed ImplementacjƒÖ

**Przygotowanie:**

1. ‚úÖ Review zespo≈Çowy tego planu (30 min meeting)
2. ‚úÖ Akceptacja Product Ownera (priorytety, bud≈ºet)
3. ‚úÖ Setup kont: Snyk, Codecov (darmowe dla OS)
4. ‚úÖ Przygotowanie ≈õrodowiska testowego (Supabase local)

**Instalacja (Faza 1, Dzie≈Ñ 1):**

```bash
# Core testing dependencies
npm install -D vitest @vitest/ui @vitest/coverage-v8 happy-dom \
  @testing-library/react @testing-library/user-event @testing-library/jest-dom \
  @playwright/test msw @faker-js/faker

# Historia (optional, dla component library)
npm install -D histoire @histoire/plugin-react

# k6 (system install, nie npm)
# https://k6.io/docs/get-started/installation/
```

**Konfiguracja (Faza 1, Dzie≈Ñ 2-3):**

- Skopiowaƒá configs z `.ai/test-configs-examples.md`
- Dostosowaƒá dla projektu (porty, URLs, env vars)
- Utworzyƒá GitHub Actions workflows
- Setup Codecov + Snyk integrations

**Proof of Concept (Faza 1, Tydzie≈Ñ 1):**

- Napisaƒá 1 unit test (ArticleService)
- Napisaƒá 1 integration test (GET /api/articles)
- Napisaƒá 1 E2E test (login flow)
- Uruchomiƒá w CI (GitHub Actions)
- Zweryfikowaƒá coverage reporting

### 11.4 Risk Assessment i Mitigation

**Potencjalne Ryzyka:**

1. **Ryzyko:** Zesp√≥≈Ç nie zna niekt√≥rych narzƒôdzi (k6, Historia)
   - **Mitigation:** Dokumentacja + training sessions (2h ka≈ºde narzƒôdzie)
   - **Probability:** Medium
   - **Impact:** Low

2. **Ryzyko:** Playwright mo≈ºe byƒá wolny na starszym CI hardware
   - **Mitigation:** Parallel execution, selective E2E runs
   - **Probability:** Low
   - **Impact:** Medium

3. **Ryzyko:** Supabase local mo≈ºe mieƒá r√≥≈ºnice vs production
   - **Mitigation:** Staging tests przed deployem, identical versions
   - **Probability:** Low
   - **Impact:** High

4. **Ryzyko:** Flaky tests w Playwright
   - **Mitigation:** Auto-wait, strict selectors, retry logic
   - **Probability:** Medium
   - **Impact:** Medium

5. **Ryzyko:** Coverage reporting mo≈ºe nie dzia≈Çaƒá dla Astro files
   - **Mitigation:** Test tylko .ts/.tsx (nie .astro), manual testing dla pages
   - **Probability:** Low
   - **Impact:** Low

**Contingency Plan:**

- Je≈õli narzƒôdzie nie dzia≈Ça: rollback do tradycyjnej alternatywy
- Budget reserve: 30h dla problem√≥w integracyjnych
- Fallback: manual testing dla krytycznych flows

### 11.5 Success Criteria (Po 6 Tygodniach)

**Minimum Viable Testing Suite:**

- ‚úÖ 50+ unit tests (coverage >70%)
- ‚úÖ 20+ integration tests (all API endpoints)
- ‚úÖ 10+ E2E tests (critical user paths)
- ‚úÖ CI/CD pipeline dzia≈ÇajƒÖcy (green builds)
- ‚úÖ 0 high/critical security issues
- ‚úÖ Performance baselines established

**Nice to Have:**

- ‚úÖ 80%+ coverage
- ‚úÖ Historia component library
- ‚úÖ Visual regression suite
- ‚úÖ Load testing automated

**Definition of Done:**

1. Wszystkie testy przechodzƒÖ w CI ‚úÖ
2. Coverage raport > threshold ‚úÖ
3. Dokumentacja kompletna ‚úÖ
4. Zesp√≥≈Ç przeszkolony ‚úÖ
5. Production deploy successful ‚úÖ

### 11.6 Linki i Zasoby

**Oficjalna Dokumentacja:**

- Vitest: https://vitest.dev/
- Playwright: https://playwright.dev/
- k6: https://k6.io/docs/
- MSW: https://mswjs.io/
- Snyk: https://docs.snyk.io/
- Trivy: https://aquasecurity.github.io/trivy/
- Historia: https://histoire.dev/

**Gotowe Konfiguracje:**

- `.ai/test-configs-examples.md` - Copy-paste configs
- `.ai/test-plan-analysis.md` - Pe≈Çna analiza rekomendacji

**Templates:**

- GitHub Issue template (sekcja 10.1)
- Bug report template
- Test file templates (w docs/)

**Kontakt:**

- QA Lead: [TBD]
- Tech Lead: [TBD]
- DevOps: [TBD]

---

**Data ostatniej aktualizacji:** Listopad 17, 2025  
**Wersja planu:** 2.0 (zaktualizowany po analizie technologicznej)  
**Autorzy:** AI Assistant + Team Review  
**Status:** ‚úÖ Gotowy do implementacji